{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":9813558,"datasetId":5925964,"databundleVersionId":10060222},{"sourceType":"datasetVersion","sourceId":9575326,"datasetId":5837237,"databundleVersionId":9794892}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"To setup the environment run the following commands on kaggle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!cp /kaggle/input/a3-1-1/A3/environment.yml /kaggle/working/\n!cp /kaggle/input/a3-1-1/A3/install.sh /kaggle/working/\n\n!bash install.sh","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:31:44.403187Z","iopub.execute_input":"2024-11-06T08:31:44.404031Z","iopub.status.idle":"2024-11-06T08:31:58.892283Z","shell.execute_reply.started":"2024-11-06T08:31:44.403990Z","shell.execute_reply":"2024-11-06T08:31:58.891305Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Installing dependencies from environment.yml using pip...\nEnvironment setup completed successfully!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Run your .py file on CLI using the following command","metadata":{}},{"cell_type":"markdown","source":"```bash\n!python bird.py path_to_dataset train bird.pth\n!python bird.py /kaggle/input/identify-the-birds/Birds/train test /kaggle/working/bird.pth\n```","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:38:39.641436Z","iopub.execute_input":"2024-11-06T05:38:39.641828Z"}}},{"cell_type":"markdown","source":"# Models to be tested\n\n### Preprocessing\n\n1. Load Images as tensors ✅ \n2. Transform the images  \n    - Padding ❌\n    - Cropping ❌\n    - Resize-ing ✅ \n3. Scale the images ✅ \n4. Normalize the images ✅ \n\n### Model Training\n\n- Normal Architecture with EffNet scaling laws ✅\n  > Compound Scaling Method ✅\n- Add BatchNorm ✅\n- Scale the network ✅\n- Add Skip Connections ✅\n- Scale the network ✅\n- Try ResNet Like Architecture ✅\n- Try GoogleNet like Architecture ❌\n- Try Removing Classimbalance by\n  1. Data Augmentation + OverSampling \n  2. Weighted Classification ❌\n  3. Weighted Sampler ❌\n  3. Focal Loss ❌\n- Learning Rate Schedulers\n  1. `StepLR` ✅\n  2. `CyclicLR` ❌\n  3. `OneCylceLR` ❌\n  4. Try Learning Rate WarmUp ❌\n- Try Label Smoothing\n- Try DropBlock and DropOut see which is better ❌\n- Check for Gradient Clipping ❌\n\n### Model Callibration\n\n- Try Model Calibration\n  1. Temperature Scaling for Calibration\n  2. Calbration with Brier Score\n \n### Visualization and Debugging\n\n- Grad-CAM\n- TensorBoard\n- Weights and Biases\n- Update Ratios","metadata":{}},{"cell_type":"markdown","source":"# Train and Test Loaders","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.colors as mcolors\nimport torch\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:32:21.178748Z","iopub.execute_input":"2024-11-06T08:32:21.179161Z","iopub.status.idle":"2024-11-06T08:32:25.485066Z","shell.execute_reply.started":"2024-11-06T08:32:21.179120Z","shell.execute_reply":"2024-11-06T08:32:25.484233Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the subfolders (0, 1, ..., 9).\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n\n        # Iterate over each subdirectory (0, 1, ..., 9)\n        for label in range(10):\n            label_dir = os.path.join(root_dir, str(label))\n            if os.path.isdir(label_dir):\n                for img_name in os.listdir(label_dir):\n                    img_path = os.path.join(label_dir, img_name)\n                    self.image_paths.append(img_path)\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:32:25.486650Z","iopub.execute_input":"2024-11-06T08:32:25.487102Z","iopub.status.idle":"2024-11-06T08:32:25.495833Z","shell.execute_reply.started":"2024-11-06T08:32:25.487067Z","shell.execute_reply":"2024-11-06T08:32:25.494788Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Calculating the Mean and Std for the dataset","metadata":{}},{"cell_type":"code","source":"# import torch\n# from torchvision import datasets, transforms\n# from torch.utils.data import DataLoader\n\n# # Define a simple transformation to just convert images to tensors\n# transform = transforms.Compose([\n#     transforms.Resize((300, 300)),\n#     transforms.ToTensor()\n# ])\n\n# # Load your dataset (replace with your dataset path)\n# dataset = ImageDataset(root_dir=\"/kaggle/input/identify-the-birds/Birds/train\", transform=transform)\n# loader = DataLoader(dataset, batch_size=200, shuffle=False)\n\n# # Function to calculate mean and std\n# def calculate_mean_std(loader):\n#     mean = 0.0\n#     std = 0.0\n#     total_images = 0\n\n#     for images, _ in loader:\n#         batch_samples = images.size(0)  # Batch size (number of images in the batch)\n#         images = images.view(batch_samples, images.size(1), -1)  # Flatten the height and width\n#         mean += images.mean(2).sum(0)\n#         std += images.std(2).sum(0)\n#         total_images += batch_samples\n\n#     mean /= total_images\n#     std /= total_images\n#     return mean, std\n\n# mean, std = calculate_mean_std(loader)\n\n# print(f\"Mean: {mean}\")\n# print(f\"Std: {std}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:32:25.496994Z","iopub.execute_input":"2024-11-06T08:32:25.497314Z","iopub.status.idle":"2024-11-06T08:32:25.508936Z","shell.execute_reply.started":"2024-11-06T08:32:25.497281Z","shell.execute_reply":"2024-11-06T08:32:25.508056Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Size - (224, 224)\n> Mean: tensor([0.4838, 0.4930, 0.4104]) \\\r\nStd: tensor([0.1881, 0.1875, 0.1886]\n\nSize - (528, 528)\n> Mean: tensor([0.4839, 0.4930, 0.4104]) \\\nStd: tensor([0.1924, 0.1919, 0.1931])\n\nSize - (300, 300)\n> Mean: tensor([0.4839, 0.4931, 0.4105]) \\\r\nStd: tensor([0.1898, 0.1892, 0.1904]))","metadata":{}},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"# Training Data Augmentation\ntrain_transform = transforms.Compose([\n    transforms.Resize((300, 300)),  # Resize to a consistent size\n    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n    transforms.RandomRotation(15),  # Randomly rotate images by up to 15 degrees\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Apply color jitter\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4838, 0.4931, 0.4105], std=[0.1924, 0.1919, 0.1931])\n])\n\n# Testing/Validation Data Transform\ntest_transform = transforms.Compose([\n    transforms.Resize((300, 300)),  # Resize to a consistent size\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4838, 0.4931, 0.4105], std=[0.1924, 0.1919, 0.1931])\n])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:32:28.667987Z","iopub.execute_input":"2024-11-06T08:32:28.668365Z","iopub.status.idle":"2024-11-06T08:32:28.676516Z","shell.execute_reply.started":"2024-11-06T08:32:28.668324Z","shell.execute_reply":"2024-11-06T08:32:28.675284Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"root_dir = \"/kaggle/input/identify-the-birds/Birds\"\ntrain_dir = os.path.join(root_dir, \"train\")\n\ndataset = ImageDataset(root_dir=train_dir)\nlabels = dataset.labels\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:57.502576Z","iopub.execute_input":"2024-11-05T17:17:57.502917Z","iopub.status.idle":"2024-11-05T17:17:58.749459Z","shell.execute_reply.started":"2024-11-05T17:17:57.502875Z","shell.execute_reply":"2024-11-05T17:17:58.748705Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Preparing Data","metadata":{}},{"cell_type":"code","source":"for train_idx, test_idx in split.split(dataset.image_paths, labels):\n    train_dataset = Subset(dataset, train_idx)\n    train_dataset.dataset.transform = train_transform\n\n    test_dataset = Subset(dataset, test_idx)\n    test_dataset.dataset.transform = test_transform","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:58.750503Z","iopub.execute_input":"2024-11-05T17:17:58.750842Z","iopub.status.idle":"2024-11-05T17:17:58.764579Z","shell.execute_reply.started":"2024-11-05T17:17:58.750806Z","shell.execute_reply":"2024-11-05T17:17:58.763733Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"batch_size = 64\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:58.765860Z","iopub.execute_input":"2024-11-05T17:17:58.766146Z","iopub.status.idle":"2024-11-05T17:17:58.771523Z","shell.execute_reply.started":"2024-11-05T17:17:58.766111Z","shell.execute_reply":"2024-11-05T17:17:58.770562Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# for idx, (images, labels) in enumerate(train_loader):\n#     print(images.shape)\n\n#     # printing the image to see\n#     image_numpy = images[0].permute(1, 2, 0).numpy()\n#     plt.imshow(image_numpy)\n#     plt.axis('off')\n#     plt.show()\n    \n#     print(labels.shape)\n#     print(idx)\n#     if (idx > 1):\n#         break","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:58.772724Z","iopub.execute_input":"2024-11-05T17:17:58.773075Z","iopub.status.idle":"2024-11-05T17:17:58.780951Z","shell.execute_reply.started":"2024-11-05T17:17:58.773031Z","shell.execute_reply":"2024-11-05T17:17:58.780080Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Getting a Base Line Model to run, to check what input size gives the best results","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torch\nimport argparse\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:42:01.699591Z","iopub.execute_input":"2024-11-06T08:42:01.700002Z","iopub.status.idle":"2024-11-06T08:42:01.705843Z","shell.execute_reply.started":"2024-11-06T08:42:01.699963Z","shell.execute_reply":"2024-11-06T08:42:01.704919Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class ResNetBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResNetBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        # Skip connection\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = self.skip(x)\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += identity\n        return self.relu(out)\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),  # Initial convolution\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n\n            # Layer 1\n            ResNetBlock(64, 64),\n            ResNetBlock(64, 64),\n\n            # Layer 2\n            ResNetBlock(64, 128, stride=2),\n            ResNetBlock(128, 128),\n\n            # Layer 3\n            ResNetBlock(128, 256, stride=2),\n            ResNetBlock(256, 256),\n\n            # Layer 4\n            ResNetBlock(256, 512, stride=2),\n            ResNetBlock(512, 512),\n\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(512, 10),  # Adjust the output layer for 8 classes\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T08:42:03.996074Z","iopub.execute_input":"2024-11-06T08:42:03.996551Z","iopub.status.idle":"2024-11-06T08:42:04.011336Z","shell.execute_reply.started":"2024-11-06T08:42:03.996506Z","shell.execute_reply":"2024-11-06T08:42:04.010299Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ----------------- model training ----------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"Available device: {device}\")\n\nmodel = CNNModel().to(device)\ncriterion = nn.CrossEntropyLoss().to(device)\nprint(f\"No. of model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:58.808727Z","iopub.execute_input":"2024-11-05T17:17:58.809030Z","iopub.status.idle":"2024-11-05T17:17:59.160149Z","shell.execute_reply.started":"2024-11-05T17:17:58.808977Z","shell.execute_reply":"2024-11-05T17:17:59.159128Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Available device: cuda\nNo. of model parameters: 11186442\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:59.161214Z","iopub.execute_input":"2024-11-05T17:17:59.161534Z","iopub.status.idle":"2024-11-05T17:17:59.200101Z","shell.execute_reply.started":"2024-11-05T17:17:59.161486Z","shell.execute_reply":"2024-11-05T17:17:59.199243Z"},"trusted":true},"outputs":[{"name":"stdout","text":"+------------------------+------------+\n|        Modules         | Parameters |\n+------------------------+------------+\n|     model.0.weight     |    9408    |\n|      model.0.bias      |     64     |\n|     model.1.weight     |     64     |\n|      model.1.bias      |     64     |\n|  model.4.conv1.weight  |   36864    |\n|   model.4.conv1.bias   |     64     |\n|   model.4.bn1.weight   |     64     |\n|    model.4.bn1.bias    |     64     |\n|  model.4.conv2.weight  |   36864    |\n|   model.4.conv2.bias   |     64     |\n|   model.4.bn2.weight   |     64     |\n|    model.4.bn2.bias    |     64     |\n|  model.5.conv1.weight  |   36864    |\n|   model.5.conv1.bias   |     64     |\n|   model.5.bn1.weight   |     64     |\n|    model.5.bn1.bias    |     64     |\n|  model.5.conv2.weight  |   36864    |\n|   model.5.conv2.bias   |     64     |\n|   model.5.bn2.weight   |     64     |\n|    model.5.bn2.bias    |     64     |\n|  model.6.conv1.weight  |   73728    |\n|   model.6.conv1.bias   |    128     |\n|   model.6.bn1.weight   |    128     |\n|    model.6.bn1.bias    |    128     |\n|  model.6.conv2.weight  |   147456   |\n|   model.6.conv2.bias   |    128     |\n|   model.6.bn2.weight   |    128     |\n|    model.6.bn2.bias    |    128     |\n| model.6.skip.0.weight  |    8192    |\n|  model.6.skip.0.bias   |    128     |\n| model.6.skip.1.weight  |    128     |\n|  model.6.skip.1.bias   |    128     |\n|  model.7.conv1.weight  |   147456   |\n|   model.7.conv1.bias   |    128     |\n|   model.7.bn1.weight   |    128     |\n|    model.7.bn1.bias    |    128     |\n|  model.7.conv2.weight  |   147456   |\n|   model.7.conv2.bias   |    128     |\n|   model.7.bn2.weight   |    128     |\n|    model.7.bn2.bias    |    128     |\n|  model.8.conv1.weight  |   294912   |\n|   model.8.conv1.bias   |    256     |\n|   model.8.bn1.weight   |    256     |\n|    model.8.bn1.bias    |    256     |\n|  model.8.conv2.weight  |   589824   |\n|   model.8.conv2.bias   |    256     |\n|   model.8.bn2.weight   |    256     |\n|    model.8.bn2.bias    |    256     |\n| model.8.skip.0.weight  |   32768    |\n|  model.8.skip.0.bias   |    256     |\n| model.8.skip.1.weight  |    256     |\n|  model.8.skip.1.bias   |    256     |\n|  model.9.conv1.weight  |   589824   |\n|   model.9.conv1.bias   |    256     |\n|   model.9.bn1.weight   |    256     |\n|    model.9.bn1.bias    |    256     |\n|  model.9.conv2.weight  |   589824   |\n|   model.9.conv2.bias   |    256     |\n|   model.9.bn2.weight   |    256     |\n|    model.9.bn2.bias    |    256     |\n| model.10.conv1.weight  |  1179648   |\n|  model.10.conv1.bias   |    512     |\n|  model.10.bn1.weight   |    512     |\n|   model.10.bn1.bias    |    512     |\n| model.10.conv2.weight  |  2359296   |\n|  model.10.conv2.bias   |    512     |\n|  model.10.bn2.weight   |    512     |\n|   model.10.bn2.bias    |    512     |\n| model.10.skip.0.weight |   131072   |\n|  model.10.skip.0.bias  |    512     |\n| model.10.skip.1.weight |    512     |\n|  model.10.skip.1.bias  |    512     |\n| model.11.conv1.weight  |  2359296   |\n|  model.11.conv1.bias   |    512     |\n|  model.11.bn1.weight   |    512     |\n|   model.11.bn1.bias    |    512     |\n| model.11.conv2.weight  |  2359296   |\n|  model.11.conv2.bias   |    512     |\n|  model.11.bn2.weight   |    512     |\n|   model.11.bn2.bias    |    512     |\n|    model.14.weight     |    5120    |\n|     model.14.bias      |     10     |\n+------------------------+------------+\nTotal Trainable Params: 11186442\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"11186442"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\n# Define optimizer and StepLR scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Decays learning rate by 0.1 every 5 epochs\n\n# Training loop\nnum_epochs = 20\n\n# Initialize logging\ntrain_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\ntrain_f1_scores, test_f1_scores = [], []\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true_train, y_pred_train = [], []  # To store true labels and predictions for F1 score\n\n    # Training phase\n    for images, labels in train_loader:\n        images = images.to(device).float()  # Move images to GPU\n        labels = labels.to(device).long()   # Move labels to GPU\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Accuracy calculation for training data\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        # Accumulate true labels and predictions for F1 score\n        y_true_train.extend(labels.cpu().numpy())  # Move labels back to CPU\n        y_pred_train.extend(predicted.cpu().numpy())  # Move predictions back to CPU\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = correct / total\n\n    # Compute F1 score for training\n    f1_macro_train = f1_score(y_true_train, y_pred_train, average='macro')\n    f1_micro_train = f1_score(y_true_train, y_pred_train, average='micro')\n    f1_train = (f1_macro_train + f1_micro_train) / 2\n\n    # Append training metrics\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    train_f1_scores.append(f1_train)\n\n    # Validation phase\n    model.eval()  # Set the model to evaluation mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true_test, y_pred_test = [], []  # To store true labels and predictions for F1 score\n\n    with torch.no_grad():  # No need to calculate gradients during validation\n        for images, labels in test_loader:\n            images = images.to(device).float()  # Move images to GPU\n            labels = labels.to(device).long()   # Move labels to GPU\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n\n            # Accuracy calculation for test data\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Accumulate true labels and predictions for F1 score\n            y_true_test.extend(labels.cpu().numpy())\n            y_pred_test.extend(predicted.cpu().numpy())\n\n    test_loss = running_loss / len(test_loader)\n    test_acc = correct / total\n\n    # Compute F1 score for validation\n    f1_macro_test = f1_score(y_true_test, y_pred_test, average='macro')\n    f1_micro_test = f1_score(y_true_test, y_pred_test, average='micro')\n    f1_test = (f1_macro_test + f1_micro_test) / 2\n\n    # Append test metrics\n    test_losses.append(test_loss)\n    test_accuracies.append(test_acc)\n    test_f1_scores.append(f1_test)\n\n    # Adjust learning rate\n    scheduler.step()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n          f'Train F1: {f1_train:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {f1_test:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-05T17:17:59.201354Z","iopub.execute_input":"2024-11-05T17:17:59.201729Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch [1/20], Train Loss: 1.4383, Train Acc: 0.4768, Train F1: 0.4719, Test Loss: 1.2977, Test Acc: 0.5572, Test F1: 0.5480\nEpoch [2/20], Train Loss: 0.8675, Train Acc: 0.7139, Train F1: 0.7127, Test Loss: 1.0646, Test Acc: 0.6837, Test F1: 0.6770\nEpoch [3/20], Train Loss: 0.6284, Train Acc: 0.7973, Train F1: 0.7958, Test Loss: 0.7431, Test Acc: 0.7555, Test F1: 0.7512\nEpoch [4/20], Train Loss: 0.4974, Train Acc: 0.8394, Train F1: 0.8376, Test Loss: 1.0821, Test Acc: 0.6862, Test F1: 0.6804\nEpoch [5/20], Train Loss: 0.4028, Train Acc: 0.8624, Train F1: 0.8605, Test Loss: 0.6944, Test Acc: 0.7826, Test F1: 0.7798\nEpoch [6/20], Train Loss: 0.2414, Train Acc: 0.9286, Train F1: 0.9270, Test Loss: 0.3691, Test Acc: 0.8865, Test F1: 0.8846\nEpoch [7/20], Train Loss: 0.1844, Train Acc: 0.9511, Train F1: 0.9498, Test Loss: 0.3599, Test Acc: 0.8931, Test F1: 0.8906\nEpoch [8/20], Train Loss: 0.1548, Train Acc: 0.9640, Train F1: 0.9630, Test Loss: 0.3364, Test Acc: 0.8941, Test F1: 0.8919\nEpoch [9/20], Train Loss: 0.1307, Train Acc: 0.9704, Train F1: 0.9695, Test Loss: 0.3458, Test Acc: 0.8911, Test F1: 0.8887\nEpoch [10/20], Train Loss: 0.1097, Train Acc: 0.9783, Train F1: 0.9776, Test Loss: 0.3364, Test Acc: 0.8976, Test F1: 0.8957\nEpoch [11/20], Train Loss: 0.0869, Train Acc: 0.9859, Train F1: 0.9855, Test Loss: 0.3194, Test Acc: 0.9026, Test F1: 0.9006\nEpoch [12/20], Train Loss: 0.0820, Train Acc: 0.9872, Train F1: 0.9868, Test Loss: 0.3192, Test Acc: 0.9046, Test F1: 0.9027\nEpoch [13/20], Train Loss: 0.0791, Train Acc: 0.9887, Train F1: 0.9884, Test Loss: 0.3219, Test Acc: 0.9036, Test F1: 0.9017\nEpoch [14/20], Train Loss: 0.0773, Train Acc: 0.9892, Train F1: 0.9888, Test Loss: 0.3184, Test Acc: 0.9051, Test F1: 0.9033\nEpoch [15/20], Train Loss: 0.0734, Train Acc: 0.9898, Train F1: 0.9895, Test Loss: 0.3195, Test Acc: 0.9031, Test F1: 0.9011\nEpoch [16/20], Train Loss: 0.0719, Train Acc: 0.9911, Train F1: 0.9908, Test Loss: 0.3222, Test Acc: 0.9006, Test F1: 0.8987\nEpoch [17/20], Train Loss: 0.0708, Train Acc: 0.9908, Train F1: 0.9906, Test Loss: 0.3209, Test Acc: 0.9006, Test F1: 0.8984\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Plotting training and validation loss curves\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plotting training and validation accuracy curves\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(test_accuracies, label='Test Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Function to calculate and plot confusion matrix\ndef plot_confusion_matrix(loader, model, device):\n    all_preds = []\n    all_labels = []\n\n    model.eval()\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device).float()\n            labels = labels.to(device).long()\n            outputs = model(images)\n\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Example usage\nplot_confusion_matrix(test_loader, model, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GRAD-CAM stuff...","metadata":{}},{"cell_type":"code","source":"dataset = ImageDataset(root_dir='/kaggle/input/identify-the-birds/Birds/train', transform=test_transform)\nloader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:37:04.526991Z","iopub.execute_input":"2024-11-06T08:37:04.527404Z","iopub.status.idle":"2024-11-06T08:37:05.299736Z","shell.execute_reply.started":"2024-11-06T08:37:04.527366Z","shell.execute_reply":"2024-11-06T08:37:05.298964Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:42:55.785983Z","iopub.execute_input":"2024-11-06T08:42:55.786389Z","iopub.status.idle":"2024-11-06T08:42:55.828408Z","shell.execute_reply.started":"2024-11-06T08:42:55.786349Z","shell.execute_reply":"2024-11-06T08:42:55.827439Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model = CNNModel().to(device)\nmodel.load_state_dict(torch.load('/kaggle/working/bird.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:44:15.048340Z","iopub.execute_input":"2024-11-06T08:44:15.049197Z","iopub.status.idle":"2024-11-06T08:44:15.443585Z","shell.execute_reply.started":"2024-11-06T08:44:15.049157Z","shell.execute_reply":"2024-11-06T08:44:15.442634Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/194968483.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/bird.pth'))\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\n\ny_hat = pd.read_csv('/kaggle/working/bird.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:49:37.487321Z","iopub.execute_input":"2024-11-06T08:49:37.488214Z","iopub.status.idle":"2024-11-06T08:49:37.503004Z","shell.execute_reply.started":"2024-11-06T08:49:37.488173Z","shell.execute_reply":"2024-11-06T08:49:37.502121Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"y_hat.loc[0].values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:52:27.151060Z","iopub.execute_input":"2024-11-06T08:52:27.151502Z","iopub.status.idle":"2024-11-06T08:52:27.158663Z","shell.execute_reply.started":"2024-11-06T08:52:27.151444Z","shell.execute_reply":"2024-11-06T08:52:27.157603Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"total = 0\ncorrect = 0\n\ny_true_labels = []\ny_hat_labels = []\n\nfor image, label in loader:\n    label = label.to(device).long()\n    if (label.item() == y_hat.loc[total].values[0]):\n        correct += 1\n    y_true_labels.append(label.item())\n    y_hat_labels.append(y_hat.loc[total].values[0])\n    total += 1\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:53:44.306409Z","iopub.execute_input":"2024-11-06T08:53:44.306807Z","iopub.status.idle":"2024-11-06T08:56:51.995300Z","shell.execute_reply.started":"2024-11-06T08:53:44.306771Z","shell.execute_reply":"2024-11-06T08:56:51.994412Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"accuracy = correct/total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:59:33.803068Z","iopub.execute_input":"2024-11-06T08:59:33.803468Z","iopub.status.idle":"2024-11-06T08:59:33.808190Z","shell.execute_reply.started":"2024-11-06T08:59:33.803431Z","shell.execute_reply":"2024-11-06T08:59:33.807159Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T08:59:36.394914Z","iopub.execute_input":"2024-11-06T08:59:36.395298Z","iopub.status.idle":"2024-11-06T08:59:36.401813Z","shell.execute_reply.started":"2024-11-06T08:59:36.395262Z","shell.execute_reply":"2024-11-06T08:59:36.400722Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.9244979919678715"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"F1 = (f1_score(y_true_labels, y_hat_labels, average='micro') + f1_score(y_true_labels, y_hat_labels, average='macro'))/2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T09:00:33.591943Z","iopub.execute_input":"2024-11-06T09:00:33.592929Z","iopub.status.idle":"2024-11-06T09:00:33.629293Z","shell.execute_reply.started":"2024-11-06T09:00:33.592875Z","shell.execute_reply":"2024-11-06T09:00:33.628311Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"F1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T09:00:36.033753Z","iopub.execute_input":"2024-11-06T09:00:36.034744Z","iopub.status.idle":"2024-11-06T09:00:36.041098Z","shell.execute_reply.started":"2024-11-06T09:00:36.034687Z","shell.execute_reply":"2024-11-06T09:00:36.040187Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0.9223807125639087"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}